{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13857f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession dan library MLlib siap.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Impor library MLlib\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    ")\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pandas as pd\n",
    "\n",
    "# Hentikan SparkSession jika ada yang aktif\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Buat SparkSession baru\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ChurnModeling\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession dan library MLlib siap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5777ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/processed_eda/train_members_grouped.parquet\"\n",
    "members_df = spark.read.parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74efbd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- msno: string (nullable = true)\n",
      " |-- is_churn: integer (nullable = true)\n",
      " |-- city: integer (nullable = true)\n",
      " |-- bd: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- registered_via: integer (nullable = true)\n",
      " |-- registration_init_time: integer (nullable = true)\n",
      " |-- bd_clean: string (nullable = true)\n",
      " |-- bd_int: integer (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "members_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76321864",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/processed_eda_rev/full_analysis_transactions.parquet\"\n",
    "transactions_df = spark.read.parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d33164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- msno: string (nullable = true)\n",
      " |-- payment_method_id: integer (nullable = true)\n",
      " |-- payment_plan_days: integer (nullable = true)\n",
      " |-- plan_list_price: integer (nullable = true)\n",
      " |-- actual_amount_paid: integer (nullable = true)\n",
      " |-- is_auto_renew: integer (nullable = true)\n",
      " |-- transaction_date: integer (nullable = true)\n",
      " |-- membership_expire_date: integer (nullable = true)\n",
      " |-- is_cancel: integer (nullable = true)\n",
      " |-- is_churn: integer (nullable = true)\n",
      " |-- city: integer (nullable = true)\n",
      " |-- bd: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- registered_via: integer (nullable = true)\n",
      " |-- registration_init_time: integer (nullable = true)\n",
      " |-- bd_clean: string (nullable = true)\n",
      " |-- bd_int: integer (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- plan_days_group: string (nullable = true)\n",
      " |-- amount_paid_group: string (nullable = true)\n",
      " |-- list_price_group: string (nullable = true)\n",
      " |-- discount_status: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "214e0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/processed_eda/plot_data_logs.parquet\"\n",
    "logs_df = spark.read.parquet(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b1461cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- msno: string (nullable = true)\n",
      " |-- is_churn: integer (nullable = true)\n",
      " |-- city: integer (nullable = true)\n",
      " |-- bd: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- registered_via: integer (nullable = true)\n",
      " |-- registration_init_time: integer (nullable = true)\n",
      " |-- bd_clean: string (nullable = true)\n",
      " |-- bd_int: integer (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- total_secs_sum: double (nullable = true)\n",
      " |-- total_active_days: long (nullable = true)\n",
      " |-- total_songs_100: long (nullable = true)\n",
      " |-- total_songs_all: long (nullable = true)\n",
      " |-- completion_rate: double (nullable = true)\n",
      " |-- listening_time_group: string (nullable = true)\n",
      " |-- active_days_group: string (nullable = true)\n",
      " |-- completion_habit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logs_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f3975d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memuat dan Menyiapkan Data untuk Age Group 0-17...\n",
      "root\n",
      " |-- msno: string (nullable = true)\n",
      " |-- is_churn: integer (nullable = true)\n",
      " |-- city: integer (nullable = true)\n",
      " |-- bd: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- registered_via: integer (nullable = true)\n",
      " |-- registration_init_time: integer (nullable = true)\n",
      " |-- bd_clean: string (nullable = true)\n",
      " |-- bd_int: integer (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- total_transactions: long (nullable = true)\n",
      " |-- total_plan_days: long (nullable = true)\n",
      " |-- total_amount_paid: long (nullable = true)\n",
      " |-- avg_amount_paid: double (nullable = false)\n",
      " |-- count_auto_renew: long (nullable = true)\n",
      " |-- count_cancel: long (nullable = true)\n",
      " |-- most_frequent_payment_method: integer (nullable = true)\n",
      " |-- total_secs_sum: double (nullable = false)\n",
      " |-- total_active_days: long (nullable = true)\n",
      " |-- total_songs_100: long (nullable = true)\n",
      " |-- completion_rate: double (nullable = false)\n",
      "\n",
      "Data Latih: 9913, Data Uji: 2439\n",
      "\n",
      "--- Melatih Model GBT ---\n",
      "\n",
      "--- Melatih Model Random Forest ---\n",
      "\n",
      "=== HASIL EVALUASI: GBT Classifier ===\n",
      "AUC-ROC : 0.8126\n",
      "AUC-PR  : 0.6569\n",
      "------------------------------\n",
      "Accuracy  : 0.7835\n",
      "Precision : 0.6757 (Ketepatan prediksi Churn)\n",
      "Recall    : 0.4363    (Daya tangkap Churn)\n",
      "F1-Score  : 0.5302\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      " TP: 298 | FP: 143\n",
      " FN: 385 | TN: 1613\n",
      "\n",
      "=== HASIL EVALUASI: Random Forest ===\n",
      "AUC-ROC : 0.8070\n",
      "AUC-PR  : 0.6369\n",
      "------------------------------\n",
      "Accuracy  : 0.7819\n",
      "Precision : 0.7127 (Ketepatan prediksi Churn)\n",
      "Recall    : 0.3704    (Daya tangkap Churn)\n",
      "F1-Score  : 0.4875\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      " TP: 253 | FP: 102\n",
      " FN: 430 | TN: 1654\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# --- 1. LOAD & PREPARE DATA (Sama seperti sebelumnya) ---\n",
    "print(\"Memuat dan Menyiapkan Data untuk Age Group 0-17...\")\n",
    "\n",
    "# Filter Age Group\n",
    "target_age_group = \"0-17 (Remaja)\"\n",
    "members_df_filtered = members_df.filter(F.col(\"age_group\") == target_age_group)\n",
    "\n",
    "# Agregasi Transaksi\n",
    "trans_agg = transactions_df.groupBy(\"msno\").agg(\n",
    "    F.count(\"payment_method_id\").alias(\"total_transactions\"),\n",
    "    F.sum(\"payment_plan_days\").alias(\"total_plan_days\"),\n",
    "    F.sum(\"actual_amount_paid\").alias(\"total_amount_paid\"),\n",
    "    F.avg(\"actual_amount_paid\").alias(\"avg_amount_paid\"),\n",
    "    F.sum(\"is_auto_renew\").alias(\"count_auto_renew\"),\n",
    "    F.sum(\"is_cancel\").alias(\"count_cancel\"),\n",
    "    F.mode(\"payment_method_id\").alias(\"most_frequent_payment_method\")\n",
    ")\n",
    "\n",
    "# Seleksi Logs\n",
    "logs_selected = logs_df.select(\n",
    "    \"msno\", \"total_secs_sum\", \"total_active_days\", \n",
    "    \"total_songs_100\", \"completion_rate\"\n",
    ")\n",
    "\n",
    "# Join & Fillna\n",
    "final_df = members_df_filtered.join(trans_agg, \"msno\", \"left\").join(logs_selected, \"msno\", \"left\")\n",
    "final_df = final_df.fillna(0, subset=[\n",
    "    \"total_transactions\", \"total_plan_days\", \"total_amount_paid\", \n",
    "    \"avg_amount_paid\", \"count_auto_renew\", \"count_cancel\",\n",
    "    \"total_secs_sum\", \"total_active_days\", \"total_songs_100\", \"completion_rate\",\n",
    "    \"most_frequent_payment_method\"\n",
    "])\n",
    "final_df = final_df.fillna(\"Unknown\", subset=[\"city\", \"registered_via\"])\n",
    "\n",
    "# Drop Columns\n",
    "cols_to_drop = [\"msno\", \"bd\", \"bd_clean\", \"bd_int\", \"registration_init_time\", \"gender\", \"age_group\"]\n",
    "final_df_model = final_df.drop(*cols_to_drop)\n",
    "final_df.printSchema()\n",
    "\n",
    "# --- 2. BUILD PIPELINE STAGES (PREPROCESSING) ---\n",
    "\n",
    "label_col = \"is_churn\"\n",
    "feature_cols = [c for c in final_df_model.columns if c != label_col]\n",
    "cat_cols = [c for c in feature_cols if c in [\"city\", \"registered_via\", \"most_frequent_payment_method\"]]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "stages = []\n",
    "\n",
    "# Categorical -> Index -> Vector\n",
    "for col in cat_cols:\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid=\"keep\")\n",
    "    encoder = OneHotEncoder(inputCols=[f\"{col}_idx\"], outputCols=[f\"{col}_vec\"])\n",
    "    stages += [indexer, encoder]\n",
    "\n",
    "# Numeric -> Vector -> Scaled\n",
    "num_assembler = VectorAssembler(inputCols=num_cols, outputCol=\"num_features_raw\")\n",
    "scaler = StandardScaler(inputCol=\"num_features_raw\", outputCol=\"num_features_scaled\")\n",
    "stages += [num_assembler, scaler]\n",
    "\n",
    "# Combine All -> Features\n",
    "input_vecs = [f\"{c}_vec\" for c in cat_cols] + [\"num_features_scaled\"]\n",
    "final_assembler = VectorAssembler(inputCols=input_vecs, outputCol=\"features\")\n",
    "stages += [final_assembler]\n",
    "\n",
    "# --- 3. TRAINING DUA MODEL (GBT & RF) ---\n",
    "\n",
    "# Split Data\n",
    "train_data, test_data = final_df_model.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Data Latih: {train_data.count()}, Data Uji: {test_data.count()}\")\n",
    "\n",
    "\n",
    "# Definisi Model\n",
    "gbt = GBTClassifier(labelCol=label_col, featuresCol=\"features\", maxIter=20, seed=42)\n",
    "rf = RandomForestClassifier(labelCol=label_col, featuresCol=\"features\", numTrees=50, seed=42)\n",
    "\n",
    "# Pipeline khusus tiap model\n",
    "pipeline_gbt = Pipeline(stages=stages + [gbt])\n",
    "pipeline_rf = Pipeline(stages=stages + [rf])\n",
    "\n",
    "print(\"\\n--- Melatih Model GBT ---\")\n",
    "model_gbt = pipeline_gbt.fit(train_data)\n",
    "preds_gbt = model_gbt.transform(test_data)\n",
    "\n",
    "print(\"\\n--- Melatih Model Random Forest ---\")\n",
    "model_rf = pipeline_rf.fit(train_data)\n",
    "preds_rf = model_rf.transform(test_data)\n",
    "\n",
    "# --- 4. FUNGSI EVALUASI LENGKAP ---\n",
    "\n",
    "def evaluate_model_complete(predictions, model_name):\n",
    "    print(f\"\\n=== HASIL EVALUASI: {model_name} ===\")\n",
    "    \n",
    "    # 1. Hitung AUC (ROC & PR)\n",
    "    evaluator_roc = BinaryClassificationEvaluator(labelCol=label_col, metricName=\"areaUnderROC\")\n",
    "    evaluator_pr = BinaryClassificationEvaluator(labelCol=label_col, metricName=\"areaUnderPR\")\n",
    "    \n",
    "    auc_roc = evaluator_roc.evaluate(predictions)\n",
    "    auc_pr = evaluator_pr.evaluate(predictions)\n",
    "    \n",
    "    print(f\"AUC-ROC : {auc_roc:.4f}\")\n",
    "    print(f\"AUC-PR  : {auc_pr:.4f}\")\n",
    "    \n",
    "    # 2. Hitung Confusion Matrix Manual untuk Metrik Detail\n",
    "    # Kita convert ke Pandas (aman karena hasil agregasi kecil)\n",
    "    cm = predictions.groupBy(label_col, \"prediction\").count().toPandas()\n",
    "    \n",
    "    # Ekstrak TP, TN, FP, FN\n",
    "    try:\n",
    "        tn = cm[(cm[label_col]==0) & (cm['prediction']==0)]['count'].values[0]\n",
    "    except: tn = 0\n",
    "    \n",
    "    try:\n",
    "        fp = cm[(cm[label_col]==0) & (cm['prediction']==1)]['count'].values[0]\n",
    "    except: fp = 0\n",
    "        \n",
    "    try:\n",
    "        fn = cm[(cm[label_col]==1) & (cm['prediction']==0)]['count'].values[0]\n",
    "    except: fn = 0\n",
    "        \n",
    "    try:\n",
    "        tp = cm[(cm[label_col]==1) & (cm['prediction']==1)]['count'].values[0]\n",
    "    except: tp = 0\n",
    "    \n",
    "    # Hitung Rumus\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Accuracy  : {accuracy:.4f}\")\n",
    "    print(f\"Precision : {precision:.4f} (Ketepatan prediksi Churn)\")\n",
    "    print(f\"Recall    : {recall:.4f}    (Daya tangkap Churn)\")\n",
    "    print(f\"F1-Score  : {f1_score:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Confusion Matrix:\\n TP: {tp} | FP: {fp}\")\n",
    "    print(f\" FN: {fn} | TN: {tn}\")\n",
    "\n",
    "# --- 5. PRINT HASIL ---\n",
    "evaluate_model_complete(preds_gbt, \"GBT Classifier\")\n",
    "evaluate_model_complete(preds_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff1eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HASIL EVALUASI: GBT Classifier ===\n",
      "AUC-ROC : 0.8126\n",
      "AUC-PR  : 0.6569\n",
      "------------------------------\n",
      "Accuracy  : 0.7835\n",
      "Precision : 0.6757 (Ketepatan prediksi Churn)\n",
      "Recall    : 0.4363    (Daya tangkap Churn)\n",
      "F1-Score  : 0.5302\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      " TP: 298 | FP: 143\n",
      " FN: 385 | TN: 1613\n",
      "\n",
      "=== HASIL EVALUASI: Random Forest ===\n",
      "AUC-ROC : 0.8070\n",
      "AUC-PR  : 0.6369\n",
      "------------------------------\n",
      "Accuracy  : 0.7819\n",
      "Precision : 0.7127 (Ketepatan prediksi Churn)\n",
      "Recall    : 0.3704    (Daya tangkap Churn)\n",
      "F1-Score  : 0.4875\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      " TP: 253 | FP: 102\n",
      " FN: 430 | TN: 1654\n"
     ]
    }
   ],
   "source": [
    "# --- 4. FUNGSI EVALUASI LENGKAP ---\n",
    "\n",
    "def evaluate_model_complete(predictions, model_name):\n",
    "    print(f\"\\n=== HASIL EVALUASI: {model_name} ===\")\n",
    "    \n",
    "    # 1. Hitung AUC (ROC & PR)\n",
    "    evaluator_roc = BinaryClassificationEvaluator(labelCol=label_col, metricName=\"areaUnderROC\")\n",
    "    evaluator_pr = BinaryClassificationEvaluator(labelCol=label_col, metricName=\"areaUnderPR\")\n",
    "    \n",
    "    auc_roc = evaluator_roc.evaluate(predictions)\n",
    "    auc_pr = evaluator_pr.evaluate(predictions)\n",
    "    \n",
    "    print(f\"AUC-ROC : {auc_roc:.4f}\")\n",
    "    print(f\"AUC-PR  : {auc_pr:.4f}\")\n",
    "    \n",
    "    # 2. Hitung Confusion Matrix Manual untuk Metrik Detail\n",
    "    # Kita convert ke Pandas (aman karena hasil agregasi kecil)\n",
    "    cm = predictions.groupBy(label_col, \"prediction\").count().toPandas()\n",
    "    \n",
    "    # Ekstrak TP, TN, FP, FN\n",
    "    try:\n",
    "        tn = cm[(cm[label_col]==0) & (cm['prediction']==0)]['count'].values[0]\n",
    "    except: tn = 0\n",
    "    \n",
    "    try:\n",
    "        fp = cm[(cm[label_col]==0) & (cm['prediction']==1)]['count'].values[0]\n",
    "    except: fp = 0\n",
    "        \n",
    "    try:\n",
    "        fn = cm[(cm[label_col]==1) & (cm['prediction']==0)]['count'].values[0]\n",
    "    except: fn = 0\n",
    "        \n",
    "    try:\n",
    "        tp = cm[(cm[label_col]==1) & (cm['prediction']==1)]['count'].values[0]\n",
    "    except: tp = 0\n",
    "    \n",
    "    # Hitung Rumus\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Accuracy  : {accuracy:.4f}\")\n",
    "    print(f\"Precision : {precision:.4f} (Ketepatan prediksi Churn)\")\n",
    "    print(f\"Recall    : {recall:.4f}    (Daya tangkap Churn)\")\n",
    "    print(f\"F1-Score  : {f1_score:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Confusion Matrix:\\n TP: {tp} | FP: {fp}\")\n",
    "    print(f\" FN: {fn} | TN: {tn}\")\n",
    "\n",
    "# --- 5. PRINT HASIL ---\n",
    "evaluate_model_complete(preds_gbt, \"GBT Classifier\")\n",
    "evaluate_model_complete(preds_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cf760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur Kategorikal: ['city', 'registered_via', 'age_group', 'most_frequent_payment_method']\n",
      "Melatih Model GBT (Tuned)...\n",
      "Evaluasi...\n",
      "\n",
      "=== HASIL EVALUASI: GBT Classifier (Tuned + Full Data) ===\n",
      "AUC-ROC : 0.9587\n",
      "AUC-PR  : 0.7047\n",
      "------------------------------\n",
      "Accuracy  : 0.8497\n",
      "Precision : 0.3788 (Ketepatan prediksi Churn)\n",
      "Recall    : 0.9680    (Daya tangkap Churn)\n",
      "F1-Score  : 0.5445\n",
      "------------------------------\n",
      "Confusion Matrix:\n",
      " TP: 19444 | FP: 31892\n",
      " FN: 642 | TN: 164547\n"
     ]
    }
   ],
   "source": [
    "# trans_agg = transactions_df.groupBy(\"msno\").agg(\n",
    "#     F.count(\"payment_method_id\").alias(\"total_transactions\"),\n",
    "#     F.sum(\"payment_plan_days\").alias(\"total_plan_days\"),\n",
    "#     F.sum(\"actual_amount_paid\").alias(\"total_amount_paid\"),\n",
    "#     F.avg(\"actual_amount_paid\").alias(\"avg_amount_paid\"),\n",
    "#     F.sum(\"is_auto_renew\").alias(\"count_auto_renew\"),\n",
    "#     F.sum(\"is_cancel\").alias(\"count_cancel\"),\n",
    "#     F.mode(\"payment_method_id\").alias(\"most_frequent_payment_method\")\n",
    "# )\n",
    "\n",
    "# # Logs (Sama)\n",
    "# logs_selected = logs_df.select(\"msno\", \"total_secs_sum\", \"total_active_days\", \"total_songs_100\", \"completion_rate\")\n",
    "\n",
    "# # Join Semua\n",
    "# final_df = members_df.join(trans_agg, \"msno\", \"left\").join(logs_selected, \"msno\", \"left\")\n",
    "\n",
    "# # Fillna\n",
    "# final_df = final_df.fillna(0, subset=[\n",
    "#     \"total_transactions\", \"total_plan_days\", \"total_amount_paid\", \n",
    "#     \"avg_amount_paid\", \"count_auto_renew\", \"count_cancel\",\n",
    "#     \"total_secs_sum\", \"total_active_days\", \"total_songs_100\", \"completion_rate\",\n",
    "#     \"most_frequent_payment_method\"\n",
    "# ])\n",
    "# final_df = final_df.fillna(\"Unknown\", subset=[\"city\", \"registered_via\", \"age_group\"])\n",
    "\n",
    "# # DROP Columns (TAPI 'age_group' DISIMPAN!)\n",
    "# cols_to_drop = [\"msno\", \"bd\", \"bd_clean\", \"bd_int\", \"registration_init_time\", \"gender\"] \n",
    "# final_df_model = final_df.drop(*cols_to_drop)\n",
    "\n",
    "# # --- 2. PIPELINE (DENGAN AGE GROUP) ---\n",
    "# label_col = \"is_churn\"\n",
    "# feature_cols = [c for c in final_df_model.columns if c != label_col]\n",
    "# # Masukkan age_group ke kategorikal\n",
    "# cat_cols = [c for c in feature_cols if c in [\"city\", \"registered_via\", \"most_frequent_payment_method\", \"age_group\"]]\n",
    "# num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "# print(\"Fitur Kategorikal:\", cat_cols)\n",
    "\n",
    "# stages = []\n",
    "# for col in cat_cols:\n",
    "#     indexer = StringIndexer(inputCol=col, outputCol=f\"{col}_idx\", handleInvalid=\"keep\")\n",
    "#     encoder = OneHotEncoder(inputCols=[f\"{col}_idx\"], outputCols=[f\"{col}_vec\"])\n",
    "#     stages += [indexer, encoder]\n",
    "\n",
    "# num_assembler = VectorAssembler(inputCols=num_cols, outputCol=\"num_features_raw\")\n",
    "# scaler = StandardScaler(inputCol=\"num_features_raw\", outputCol=\"num_features_scaled\")\n",
    "# stages += [num_assembler, scaler]\n",
    "\n",
    "# input_vecs = [f\"{c}_vec\" for c in cat_cols] + [\"num_features_scaled\"]\n",
    "# final_assembler = VectorAssembler(inputCols=input_vecs, outputCol=\"features\")\n",
    "# stages += [final_assembler]\n",
    "\n",
    "# # --- 3. MODEL YANG LEBIH KUAT (TUNED HYPERPARAMETERS) ---\n",
    "# # Kita naikkan maxIter dan maxDepth agar model lebih pintar\n",
    "# gbt = GBTClassifier(\n",
    "#     labelCol=label_col, \n",
    "#     featuresCol=\"features\", \n",
    "#     maxIter=100,    # Naik dari 20 -> 100 (Belajar lebih lama)\n",
    "#     maxDepth=5,     # Pohon lebih dalam (menangkap pola kompleks)\n",
    "#     stepSize=0.1,   # Learning rate standar\n",
    "#     seed=42\n",
    "# )\n",
    "# stages.append(gbt)\n",
    "# pipeline = Pipeline(stages=stages)\n",
    "\n",
    "# # --- 4. SPLIT & OVERSAMPLING (SAMA SEPERTI SEBELUMNYA) ---\n",
    "# train_data, test_data = final_df_model.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# # Oversampling Logic (Wajib untuk Imbalance)\n",
    "# major_df = train_data.filter(F.col(label_col) == 0)\n",
    "# minor_df = train_data.filter(F.col(label_col) == 1)\n",
    "# ratio = major_df.count() / minor_df.count()\n",
    "# minor_oversampled = minor_df.sample(withReplacement=True, fraction=ratio, seed=42)\n",
    "# train_data_balanced = major_df.unionAll(minor_oversampled)\n",
    "\n",
    "# print(\"Melatih Model GBT (Tuned)...\")\n",
    "# model = pipeline.fit(train_data_balanced)\n",
    "\n",
    "# print(\"Evaluasi...\")\n",
    "# predictions = model.transform(test_data)\n",
    "# evaluate_model_complete(predictions, \"GBT Classifier (Tuned + Full Data)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
