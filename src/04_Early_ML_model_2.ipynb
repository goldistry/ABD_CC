{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6debe259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession dan library MLlib siap.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Impor library MLlib\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import (\n",
    "    StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    ")\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    ")\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pandas as pd\n",
    "\n",
    "# Hentikan SparkSession jika ada yang aktif\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Buat SparkSession baru\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ChurnModeling\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"SparkSession dan library MLlib siap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb714f",
   "metadata": {},
   "source": [
    "# Load Data & Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f56dbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature selection selesai. Skema akhir untuk model:\n",
      "root\n",
      " |-- is_churn: integer (nullable = true)\n",
      " |-- city: integer (nullable = true)\n",
      " |-- age_group: string (nullable = true)\n",
      " |-- total_transactions: long (nullable = true)\n",
      " |-- total_payment_plan_days: long (nullable = true)\n",
      " |-- avg_discount: double (nullable = true)\n",
      " |-- count_cancel: long (nullable = true)\n",
      " |-- days_since_last_activity: integer (nullable = true)\n",
      " |-- total_secs_last_30d: double (nullable = true)\n",
      " |-- active_days_last_30d: long (nullable = true)\n",
      " |-- activity_ratio_secs: double (nullable = true)\n",
      " |-- percent_complete_last_30d: double (nullable = true)\n",
      " |-- lifetime_active_days: long (nullable = true)\n",
      " |-- lifetime_unq_songs: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 1. Muat data master_feature_table_3.parquet\n",
    "data_path = \"data/master_feature_table_3.parquet\"\n",
    "df = spark.read.parquet(data_path)\n",
    "df.cache()\n",
    "\n",
    "# 2. Daftar Fitur yang DIBUANG (Berdasarkan EDA & Korelasi)\n",
    "cols_to_drop = [\n",
    "    \"msno\",                     # ID\n",
    "    \"last_transaction_date\",    # Format tanggal\n",
    "    \"last_expiry_date\",         # Format tanggal\n",
    "    \n",
    "    # --- Berdasarkan Temuan EDA Correlation ---\n",
    "    # Dibuang karena Redundant (Korelasi > 0.85)\n",
    "    \"count_auto_renew\",\n",
    "    #\"total_transactions\",       # Korelasi 0.91 dg count_auto_renew\n",
    "    #\"total_payment_plan_days\",  # Korelasi 0.88 dg total_transactions\n",
    "    \"total_secs_last_90d\",      # Korelasi 0.94 dg total_secs_last_30d\n",
    "    \"active_days_last_90d\",     # Korelasi 0.94 dg active_days_last_30d\n",
    "    \n",
    "    # Dibuang karena Tidak Prediktif (Berdasarkan EDA)\n",
    "    \"membership_duration_days\",\n",
    "    \"registered_via\",\n",
    "    #\"city\"\n",
    "    #\"lifetime_active_days\",\n",
    "    #\"lifetime_unq_songs\",\n",
    "    \n",
    "]\n",
    "\n",
    "# 3. Terapkan Feature Selection\n",
    "df_selected = df.drop(*cols_to_drop)\n",
    "\n",
    "print(\"Feature selection selesai. Skema akhir untuk model:\")\n",
    "df_selected.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5589088e",
   "metadata": {},
   "source": [
    "# Define Features Type & Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur Kategorikal: ['age_group', 'city']\n",
      "Fitur Numerik: ['total_transactions', 'total_payment_plan_days', 'avg_discount', 'count_cancel', 'days_since_last_activity', 'total_secs_last_30d', 'active_days_last_30d', 'activity_ratio_secs', 'percent_complete_last_30d', 'lifetime_active_days']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# define tipe fitur& pipeline preprocessing\n",
    "# 1. Tentukan fitur kategorikal dan numerik (dari sisa kolom)\n",
    "#categorical_cols = [\"age_group\", \"city\", \"registered_via\"]\n",
    "categorical_cols = [\"age_group\", \"city\"]\n",
    "#categorical_cols = [\"age_group\"]\n",
    "\n",
    "# Semua kolom lain selain 'is_churn' dan kategorikal adalah numerik\n",
    "numerical_cols = [\n",
    "    col for col in df_selected.columns \n",
    "    if col not in categorical_cols + [\"is_churn\"]\n",
    "]\n",
    "\n",
    "print(f\"Fitur Kategorikal: {categorical_cols}\")\n",
    "print(f\"Fitur Numerik: {numerical_cols}\")\n",
    "\n",
    "# --- TAHAPAN PIPELINE PREPROCESSING ---\n",
    "\n",
    "# Tahap 1: StringIndexer (Hanya untuk 'age_group' karena 'city' & 'registered_via' sudah angka)\n",
    "# Kita perlu mengubah \"Unknown\", \"18-25\" menjadi 0.0, 1.0, dst.\n",
    "indexer = StringIndexer(\n",
    "    inputCol=\"age_group\", \n",
    "    outputCol=\"age_group_idx\", \n",
    "    handleInvalid=\"keep\" # Mengubah null/unknown menjadi indeks khusus\n",
    ")\n",
    "\n",
    "# Tahap 2: OneHotEncoder (Untuk SEMUA kategorikal)\n",
    "# Mengubah [0.0, 1.0, 2.0] menjadi vector [1,0,0], [0,1,0], [0,0,1]\n",
    "encoder = OneHotEncoder(\n",
    "    #inputCols=[\"age_group_idx\", \"city\", \"registered_via\"],\n",
    "    inputCols=[\"age_group_idx\", \"city\"],\n",
    "    #outputCols=[\"age_group_vec\", \"city_vec\", \"registered_via_vec\"]\n",
    "    outputCols=[\"age_group_vec\" , \"city_vec\"]\n",
    ")\n",
    "\n",
    "# Tahap 3: VectorAssembler (Hanya untuk fitur NUMERIK)\n",
    "assembler_num = VectorAssembler(\n",
    "    inputCols=numerical_cols, \n",
    "    outputCol=\"numerical_features\"\n",
    ")\n",
    "\n",
    "# Tahap 4: StandardScaler (Untuk fitur numerik)\n",
    "# Menyamakan skala semua fitur numerik (penting untuk Logistic Regression)\n",
    "scaler = StandardScaler(\n",
    "    inputCol=\"numerical_features\", \n",
    "    outputCol=\"scaled_numerical_features\"\n",
    ")\n",
    "\n",
    "# Tahap 5: VectorAssembler Final (Menggabungkan SEMUA fitur)\n",
    "assembler_final = VectorAssembler(\n",
    "    inputCols=[\n",
    "        \"age_group_vec\", \n",
    "        \"city_vec\", \n",
    "        #\"registered_via_vec\", \n",
    "        \"scaled_numerical_features\"\n",
    "    ],\n",
    "    outputCol=\"features\" # Ini adalah kolom akhir yang dibutuhkan model\n",
    ")\n",
    "\n",
    "# Gabungkan semua tahapan preprocessing menjadi satu pipeline\n",
    "preprocessing_pipeline = Pipeline(\n",
    "    stages=[\n",
    "        indexer, \n",
    "        encoder, \n",
    "        assembler_num, \n",
    "        scaler, \n",
    "        assembler_final\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0905791",
   "metadata": {},
   "source": [
    "# Data Splitting & Oversampling (imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db345207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membagi data menjadi 80% Latih, 20% Uji...\n",
      "Baris data Latih (sebelum oversampling): 865,704\n",
      "Baris data Uji: 216,486\n",
      "Melakukan oversampling pada data latih...\n",
      "Rasio (0:1): 9.93 : 1\n",
      "Baris data Latih (setelah oversampling): 1,572,027\n",
      "Verifikasi data latih baru:\n",
      "+--------+------+\n",
      "|is_churn| count|\n",
      "+--------+------+\n",
      "|       0|786515|\n",
      "|       1|785512|\n",
      "+--------+------+\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Data Split & Oversampling (imbalance)\n",
    "# 1. Bagi data menjadi set Latihan (80%) dan Uji (20%)\n",
    "# stratifikasi berdasarkan 'is_churn' agar proporsinya sama\n",
    "print(\"Membagi data menjadi 80% Latih, 20% Uji...\")\n",
    "train_data, test_data = df_selected.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "train_data.cache()\n",
    "test_data.cache()\n",
    "\n",
    "train_count = train_data.count()\n",
    "test_count = test_data.count()\n",
    "\n",
    "print(f\"Baris data Latih (sebelum oversampling): {train_data.count():,}\")\n",
    "print(f\"Baris data Uji: {test_data.count():,}\")\n",
    "\n",
    "# 2. Lakukan Oversampling pada Data Latih (HANYA PADA TRAIN_DATA)\n",
    "print(\"Melakukan oversampling pada data latih...\")\n",
    "\n",
    "# Hitung rasio imbalance\n",
    "count_class_0 = train_data.filter(col(\"is_churn\") == 0).count()\n",
    "count_class_1 = train_data.filter(col(\"is_churn\") == 1).count()\n",
    "ratio = 10%\n",
    "\n",
    "print(f\"Rasio (0:1): {ratio:.2f} : 1\")\n",
    "\n",
    "# Pisahkan kelas\n",
    "df_majority = train_data.filter(col(\"is_churn\") == 0)\n",
    "df_minority = train_data.filter(col(\"is_churn\") == 1)\n",
    "\n",
    "# Lakukan oversampling (duplikasi acak) pada kelas minoritas\n",
    "df_minority_oversampled = df_minority.sample(\n",
    "    withReplacement=True, \n",
    "    fraction=ratio, \n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Gabungkan kembali menjadi data latih yang seimbang\n",
    "train_data_oversampled = df_majority.unionAll(df_minority_oversampled)\n",
    "\n",
    "print(f\"Baris data Latih (setelah oversampling): {train_data_oversampled.count():,}\")\n",
    "print(\"Verifikasi data latih baru:\")\n",
    "train_data_oversampled.groupBy(\"is_churn\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917371a4",
   "metadata": {},
   "source": [
    "# Define Model & Train Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda1165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melatih Logistic Regression...\n",
      "Melatih Random Forest...\n",
      "Melatih GBT...\n",
      "Semua model selesai dilatih.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# define model & train pipeline\n",
    "# 1. Definisikan 3 model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"is_churn\")\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"is_churn\", seed=42)\n",
    "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"is_churn\", seed=42)\n",
    "\n",
    "# 2. Buat pipeline lengkap (Preprocessing + Model)\n",
    "pipeline_lr = Pipeline(stages=[preprocessing_pipeline, lr])\n",
    "pipeline_rf = Pipeline(stages=[preprocessing_pipeline, rf])\n",
    "pipeline_gbt = Pipeline(stages=[preprocessing_pipeline, gbt])\n",
    "\n",
    "# 3. Latih model\n",
    "# Model dilatih pada data latih yang sudah SEIMBANG (Oversampled)\n",
    "print(\"Melatih Logistic Regression...\")\n",
    "model_lr = pipeline_lr.fit(train_data_oversampled)\n",
    "\n",
    "print(\"Melatih Random Forest...\")\n",
    "model_rf = pipeline_rf.fit(train_data_oversampled)\n",
    "\n",
    "print(\"Melatih GBT...\")\n",
    "model_gbt = pipeline_gbt.fit(train_data_oversampled)\n",
    "\n",
    "print(\"Semua model selesai dilatih.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb06e7",
   "metadata": {},
   "source": [
    "# Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206145e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membuat prediksi pada data uji (unseen & imbalanced)...\n",
      "\n",
      "--- Hasil Evaluasi Model ---\n",
      "\n",
      "Logistic Regression:\n",
      "  AUC-ROC: 0.9064\n",
      "  AUC-PR (Fokus Churn): 0.5529\n",
      "\n",
      "Random Forest:\n",
      "  AUC-ROC: 0.9118\n",
      "  AUC-PR (Fokus Churn): 0.6462\n",
      "\n",
      "GBT Classifier:\n",
      "  AUC-ROC: 0.9535\n",
      "  AUC-PR (Fokus Churn): 0.7538\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Evaluasi Model pada Data Test (evaluasi balik ke data yg ga seimbang u/ lihat performa nyata model)\n",
    "# 1. Buat prediksi pada data UJI (yang tidak seimbang)\n",
    "print(\"Membuat prediksi pada data uji (unseen & imbalanced)...\")\n",
    "pred_lr = model_lr.transform(test_data)\n",
    "pred_rf = model_rf.transform(test_data)\n",
    "pred_gbt = model_gbt.transform(test_data)\n",
    "\n",
    "# 2. Definisikan Evaluator\n",
    "# menggunakan dua metrik utama untuk data imbalance:\n",
    "# AUC-ROC: Baik untuk mengukur performa keseluruhan\n",
    "# AUC-PR: (AreaUnderPrecisionRecall) Sangat baik untuk kelas minoritas yang langka\n",
    "\n",
    "evaluator_roc = BinaryClassificationEvaluator(\n",
    "    labelCol=\"is_churn\", \n",
    "    rawPredictionCol=\"rawPrediction\", \n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "evaluator_pr = BinaryClassificationEvaluator(\n",
    "    labelCol=\"is_churn\", \n",
    "    rawPredictionCol=\"rawPrediction\", \n",
    "    metricName=\"areaUnderPR\"\n",
    ")\n",
    "\n",
    "# 3. Hitung dan Tampilkan Hasil\n",
    "results = {}\n",
    "\n",
    "print(\"\\n--- Hasil Evaluasi Model ---\")\n",
    "\n",
    "# Logistic Regression\n",
    "auc_roc_lr = evaluator_roc.evaluate(pred_lr)\n",
    "auc_pr_lr = evaluator_pr.evaluate(pred_lr)\n",
    "results['Logistic Regression'] = {'AUC-ROC': auc_roc_lr, 'AUC-PR': auc_pr_lr}\n",
    "print(f\"\\nLogistic Regression:\")\n",
    "print(f\"  AUC-ROC: {auc_roc_lr:.4f}\")\n",
    "print(f\"  AUC-PR (Fokus Churn): {auc_pr_lr:.4f}\")\n",
    "\n",
    "# Random Forest\n",
    "auc_roc_rf = evaluator_roc.evaluate(pred_rf)\n",
    "auc_pr_rf = evaluator_pr.evaluate(pred_rf)\n",
    "results['Random Forest'] = {'AUC-ROC': auc_roc_rf, 'AUC-PR': auc_pr_rf}\n",
    "print(f\"\\nRandom Forest:\")\n",
    "print(f\"  AUC-ROC: {auc_roc_rf:.4f}\")\n",
    "print(f\"  AUC-PR (Fokus Churn): {auc_pr_rf:.4f}\")\n",
    "\n",
    "# GBT\n",
    "auc_roc_gbt = evaluator_roc.evaluate(pred_gbt)\n",
    "auc_pr_gbt = evaluator_pr.evaluate(pred_gbt)\n",
    "results['GBT'] = {'AUC-ROC': auc_roc_gbt, 'AUC-PR': auc_pr_gbt}\n",
    "print(f\"\\nGBT Classifier:\")\n",
    "print(f\"  AUC-ROC: {auc_roc_gbt:.4f}\")\n",
    "print(f\"  AUC-PR (Fokus Churn): {auc_pr_gbt:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cffea7e",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aa22e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\spark\\Lib\\site-packages\\pyspark\\sql\\context.py:157: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Confusion Matrix untuk: GBT Classifier ---\n",
      "[[179551.  17096.]\n",
      " [  2674.  17165.]]\n",
      "  Overall Accuracy:   0.9087\n",
      "  Recall (Churn=1):    0.8652\n",
      "  Precision (Churn=1): 0.5010\n",
      "  F1-Score (Churn=1):  0.6346\n",
      "\n",
      "--- Confusion Matrix untuk: Logistic Regression ---\n",
      "[[164753.  31894.]\n",
      " [  3360.  16479.]]\n",
      "  Overall Accuracy:   0.8372\n",
      "  Recall (Churn=1):    0.8306\n",
      "  Precision (Churn=1): 0.3407\n",
      "  F1-Score (Churn=1):  0.4832\n",
      "\n",
      "--- Confusion Matrix untuk: Random Forest ---\n",
      "[[170256.  26391.]\n",
      " [  4240.  15599.]]\n",
      "  Overall Accuracy:   0.8585\n",
      "  Recall (Churn=1):    0.7863\n",
      "  Precision (Churn=1): 0.3715\n",
      "  F1-Score (Churn=1):  0.5046\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def print_confusion_matrix(predictions, model_name):\n",
    "    # Mengubah prediksi menjadi RDD untuk MulticlassMetrics\n",
    "    preds_and_labels = predictions.select(\"prediction\", \"is_churn\").rdd.map(\n",
    "        lambda r: (float(r.prediction), float(r.is_churn))\n",
    "    )\n",
    "    \n",
    "    metrics = MulticlassMetrics(preds_and_labels)\n",
    "    confusion_matrix = metrics.confusionMatrix().toArray()\n",
    "    \n",
    "    print(f\"\\n--- Confusion Matrix untuk: {model_name} ---\")\n",
    "    print(confusion_matrix)\n",
    "    \n",
    "    Overall_Accuracy = metrics.accuracy\n",
    "    print(f\"  Overall Accuracy:   {Overall_Accuracy:.4f}\")\n",
    "\n",
    "    # TN, FP\n",
    "    # FN, TP\n",
    "    TN = confusion_matrix[0][0]\n",
    "    FP = confusion_matrix[0][1]\n",
    "    FN = confusion_matrix[1][0]\n",
    "    TP = confusion_matrix[1][1]\n",
    "    \n",
    "    Recall_Churn = TP / (TP + FN)\n",
    "    Precision_Churn = TP / (TP + FP)\n",
    "    F1_Churn = 2 * (Precision_Churn * Recall_Churn) / (Precision_Churn + Recall_Churn)\n",
    "    \n",
    "    print(f\"  Recall (Churn=1):    {Recall_Churn:.4f}\")\n",
    "    print(f\"  Precision (Churn=1): {Precision_Churn:.4f}\")\n",
    "    print(f\"  F1-Score (Churn=1):  {F1_Churn:.4f}\")\n",
    "\n",
    "# model terbaik (GBT)\n",
    "print_confusion_matrix(pred_gbt, \"GBT Classifier\")\n",
    "\n",
    "# Logistic Regression\n",
    "print_confusion_matrix(pred_lr, \"Logistic Regression\")\n",
    "\n",
    "# Random Forest\n",
    "print_confusion_matrix(pred_rf, \"Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98684da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencari nilai unik untuk kolom 'city'...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'master_table_spark_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMencari nilai unik untuk kolom \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcity\u001b[39m\u001b[33m'\u001b[39m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 1. Pilih kolom 'city'\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# 2. Ambil nilai unik dengan .distinct()\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 3. Urutkan hasilnya agar mudah dibaca\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m unique_cities_df = \u001b[43mmaster_table_spark_3\u001b[49m.select(\u001b[33m\"\u001b[39m\u001b[33mcity\u001b[39m\u001b[33m\"\u001b[39m).distinct().orderBy(\u001b[33m\"\u001b[39m\u001b[33mcity\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Tampilkan hasilnya\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Kita gunakan n=30, yang seharusnya cukup untuk ID kota\u001b[39;00m\n\u001b[32m     12\u001b[39m unique_cities_df.show(\u001b[32m30\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'master_table_spark_3' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "print(\"Mencari nilai unik untuk kolom 'city'...\")\n",
    "\n",
    "# 1. Pilih kolom 'city'\n",
    "# 2. Ambil nilai unik dengan .distinct()\n",
    "# 3. Urutkan hasilnya agar mudah dibaca\n",
    "unique_cities_df = master_table_spark_3.select(\"city\").distinct().orderBy(\"city\")\n",
    "\n",
    "# Tampilkan hasilnya\n",
    "# Kita gunakan n=30, yang seharusnya cukup untuk ID kota\n",
    "unique_cities_df.show(30)\n",
    "\n",
    "# Hitung jumlah total nilai unik\n",
    "count = unique_cities_df.count()\n",
    "print(f\"Total nilai unik (distinct) di kolom 'city': {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c122dcba",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
